{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 156\u001b[0m\n\u001b[1;32m    152\u001b[0m         cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m1\u001b[39m)\n\u001b[1;32m    155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 156\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn [3], line 145\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     success, img \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()\n\u001b[0;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m detector\u001b[39m.\u001b[39;49mfindPose(img)\n\u001b[1;32m    146\u001b[0m     lmList, bboxInfo \u001b[39m=\u001b[39m detector\u001b[39m.\u001b[39mfindPosition(img, bboxWithHands\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    147\u001b[0m    \u001b[39m# if bboxInfo:\u001b[39;00m\n\u001b[1;32m    148\u001b[0m     \u001b[39m#    center = bboxInfo[\"center\"]\u001b[39;00m\n\u001b[1;32m    149\u001b[0m       \u001b[39m#  cv2.circle(img, center, 5, (255, 0, 255), cv2.FILLED)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [3], line 46\u001b[0m, in \u001b[0;36mPoseDetector.findPose\u001b[0;34m(self, img, draw)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mFind the pose landmarks in an Image of BGR color space.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39m:param img: Image to find the pose in.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m:param draw: Flag to draw the output on the image.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39m:return: Image with or without drawings\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m imgRGB \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m---> 46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpose\u001b[39m.\u001b[39;49mprocess(imgRGB)\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults\u001b[39m.\u001b[39mpose_landmarks:\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m draw:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/mediapipe/python/solutions/pose.py:185\u001b[0m, in \u001b[0;36mPose.process\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess\u001b[39m(\u001b[39mself\u001b[39m, image: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NamedTuple:\n\u001b[1;32m    165\u001b[0m   \u001b[39m\"\"\"Processes an RGB image and returns the pose landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[1;32m    167\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mprocess(input_data\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m: image})\n\u001b[1;32m    186\u001b[0m   \u001b[39mif\u001b[39;00m results\u001b[39m.\u001b[39mpose_landmarks:  \u001b[39m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[39mfor\u001b[39;00m landmark \u001b[39min\u001b[39;00m results\u001b[39m.\u001b[39mpose_landmarks\u001b[39m.\u001b[39mlandmark:  \u001b[39m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/mediapipe/python/solution_base.py:366\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39madd_packet_to_input_stream(\n\u001b[1;32m    362\u001b[0m         stream\u001b[39m=\u001b[39mstream_name,\n\u001b[1;32m    363\u001b[0m         packet\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_packet(input_stream_type,\n\u001b[1;32m    364\u001b[0m                                  data)\u001b[39m.\u001b[39mat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_simulated_timestamp))\n\u001b[0;32m--> 366\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph\u001b[39m.\u001b[39;49mwait_until_idle()\n\u001b[1;32m    367\u001b[0m \u001b[39m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[39m# output stream names.\u001b[39;00m\n\u001b[1;32m    369\u001b[0m solution_outputs \u001b[39m=\u001b[39m collections\u001b[39m.\u001b[39mnamedtuple(\n\u001b[1;32m    370\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSolutionOutputs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_stream_type_info\u001b[39m.\u001b[39mkeys())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pose Module\n",
    "By: Computer Vision Zone\n",
    "Website: https://www.computervision.zone/\n",
    "\"\"\"\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "\n",
    "\n",
    "class PoseDetector:\n",
    "    \"\"\"\n",
    "    Estimates Pose points of a human body using the mediapipe library.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mode=False, smooth=True,\n",
    "                 detectionCon=0.5, trackCon=0.5):\n",
    "        \"\"\"\n",
    "        :param mode: In static mode, detection is done on each image: slower\n",
    "        :param upBody: Upper boy only flag\n",
    "        :param smooth: Smoothness Flag\n",
    "        :param detectionCon: Minimum Detection Confidence Threshold\n",
    "        :param trackCon: Minimum Tracking Confidence Threshold\n",
    "        \"\"\"\n",
    "\n",
    "        self.mode = mode\n",
    "        self.smooth = smooth\n",
    "        self.detectionCon = detectionCon\n",
    "        self.trackCon = trackCon\n",
    "\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "        self.mpPose = mp.solutions.pose\n",
    "        self.pose = self.mpPose.Pose(static_image_mode=self.mode,\n",
    "                                     smooth_landmarks=self.smooth,\n",
    "                                     min_detection_confidence=self.detectionCon,\n",
    "                                     min_tracking_confidence=self.trackCon)\n",
    "\n",
    "    def findPose(self, img, draw=True):\n",
    "        \"\"\"\n",
    "        Find the pose landmarks in an Image of BGR color space.\n",
    "        :param img: Image to find the pose in.\n",
    "        :param draw: Flag to draw the output on the image.\n",
    "        :return: Image with or without drawings\n",
    "        \"\"\"\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.pose.process(imgRGB)\n",
    "        if self.results.pose_landmarks:\n",
    "            if draw:\n",
    "                self.mpDraw.draw_landmarks(img, self.results.pose_landmarks,\n",
    "                                           self.mpPose.POSE_CONNECTIONS)\n",
    "        return img\n",
    "\n",
    "    def findPosition(self, img, draw=True, bboxWithHands=False):\n",
    "        self.lmList = []\n",
    "        self.bboxInfo = {}\n",
    "        if self.results.pose_landmarks:\n",
    "            for id, lm in enumerate(self.results.pose_landmarks.landmark):\n",
    "                h, w, c = img.shape\n",
    "                cx, cy, cz = int(lm.x * w), int(lm.y * h), int(lm.z * w)\n",
    "                self.lmList.append([id, cx, cy, cz])\n",
    "\n",
    "            # Bounding Box\n",
    "            ad = abs(self.lmList[12][1] - self.lmList[11][1]) // 2\n",
    "            if bboxWithHands:\n",
    "                x1 = self.lmList[16][1] - ad\n",
    "                x2 = self.lmList[15][1] + ad\n",
    "            else:\n",
    "                x1 = self.lmList[12][1] - ad\n",
    "                x2 = self.lmList[11][1] + ad\n",
    "\n",
    "            y2 = self.lmList[29][2] + ad\n",
    "            y1 = self.lmList[1][2] - ad\n",
    "            bbox = (x1, y1, x2 - x1, y2 - y1)\n",
    "            cx, cy = bbox[0] + (bbox[2] // 2), \\\n",
    "                     bbox[1] + bbox[3] // 2\n",
    "\n",
    "            self.bboxInfo = {\"bbox\": bbox, \"center\": (cx, cy)}\n",
    "\n",
    "            if draw:\n",
    "                cv2.rectangle(img, bbox, (255, 0, 255), 3)\n",
    "                cv2.circle(img, (cx, cy), 5, (255, 0, 0), cv2.FILLED)\n",
    "\n",
    "        return self.lmList, self.bboxInfo\n",
    "\n",
    "    def findAngle(self, img, p1, p2, p3, draw=True):\n",
    "        \"\"\"\n",
    "        Finds angle between three points. Inputs index values of landmarks\n",
    "        instead of the actual points.\n",
    "        :param img: Image to draw output on.\n",
    "        :param p1: Point1 - Index of Landmark 1.\n",
    "        :param p2: Point2 - Index of Landmark 2.\n",
    "        :param p3: Point3 - Index of Landmark 3.\n",
    "        :param draw:  Flag to draw the output on the image.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the landmarks\n",
    "        x1, y1 = self.lmList[p1][1:]\n",
    "        x2, y2 = self.lmList[p2][1:]\n",
    "        x3, y3 = self.lmList[p3][1:]\n",
    "\n",
    "        # Calculate the Angle\n",
    "        angle = math.degrees(math.atan2(y3 - y2, x3 - x2) -\n",
    "                             math.atan2(y1 - y2, x1 - x2))\n",
    "        if angle < 0:\n",
    "            angle += 360\n",
    "\n",
    "        # Draw\n",
    "        if draw:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), (255, 255, 255), 3)\n",
    "            cv2.line(img, (x3, y3), (x2, y2), (255, 255, 255), 3)\n",
    "            cv2.circle(img, (x1, y1), 10, (0, 0, 255), cv2.FILLED)\n",
    "            cv2.circle(img, (x1, y1), 15, (0, 0, 255), 2)\n",
    "            cv2.circle(img, (x2, y2), 10, (0, 0, 255), cv2.FILLED)\n",
    "            cv2.circle(img, (x2, y2), 15, (0, 0, 255), 2)\n",
    "            cv2.circle(img, (x3, y3), 10, (0, 0, 255), cv2.FILLED)\n",
    "            cv2.circle(img, (x3, y3), 15, (0, 0, 255), 2)\n",
    "            cv2.putText(img, str(int(angle)), (x2 - 50, y2 + 50),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)\n",
    "        return angle\n",
    "\n",
    "    def findDistance(self, p1, p2, img, draw=True, r=15, t=3):\n",
    "        x1, y1 = self.lmList[p1][1:]\n",
    "        x2, y2 = self.lmList[p2][1:]\n",
    "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "        if draw:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), (255, 0, 255), t)\n",
    "            cv2.circle(img, (x1, y1), r, (255, 0, 255), cv2.FILLED)\n",
    "            cv2.circle(img, (x2, y2), r, (255, 0, 255), cv2.FILLED)\n",
    "            cv2.circle(img, (cx, cy), r, (0, 0, 255), cv2.FILLED)\n",
    "        length = math.hypot(x2 - x1, y2 - y1)\n",
    "\n",
    "        return length, img, [x1, y1, x2, y2, cx, cy]\n",
    "\n",
    "    def angleCheck(self, myAngle, targetAngle, addOn=20):\n",
    "        return targetAngle - addOn < myAngle < targetAngle + addOn\n",
    "\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    detector = PoseDetector()\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        img = detector.findPose(img)\n",
    "        lmList, bboxInfo = detector.findPosition(img, bboxWithHands=False)\n",
    "       # if bboxInfo:\n",
    "        #    center = bboxInfo[\"center\"]\n",
    "          #  cv2.circle(img, center, 5, (255, 0, 255), cv2.FILLED)\n",
    "\n",
    "        cv2.imshow(\"Image\", img)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (v3.10.7:6cc6b13308, Sep  5 2022, 14:02:52) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
